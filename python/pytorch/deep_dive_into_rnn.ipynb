{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep dive into RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# import matplotlib.pyplot as plt\n",
    "# import networkx as nx\n",
    "import torch\n",
    "from torch.nn import RNN\n",
    "from torch.nn import LSTM\n",
    "from torch.nn import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://networkx.org/documentation/stable/auto_examples/drawing/plot_multipartite_graph.html#\n",
    "\n",
    "\n",
    "# subset_sizes = [5, 5, 4, 3, 2, 4, 4, 3]\n",
    "# subset_color = [\n",
    "#     \"gold\",\n",
    "#     \"violet\",\n",
    "#     \"violet\",\n",
    "#     \"violet\",\n",
    "#     \"violet\",\n",
    "#     \"limegreen\",\n",
    "#     \"limegreen\",\n",
    "#     \"darkorange\",\n",
    "# ]\n",
    "\n",
    "\n",
    "# def multilayered_graph(*subset_sizes):\n",
    "#     extents = nx.utils.pairwise(itertools.accumulate((0,) + subset_sizes))\n",
    "#     layers = [range(start, end) for start, end in extents]\n",
    "#     G = nx.Graph()\n",
    "#     for i, layer in enumerate(layers):\n",
    "#         G.add_nodes_from(layer, layer=i)\n",
    "#     for layer1, layer2 in nx.utils.pairwise(layers):\n",
    "#         G.add_edges_from(itertools.product(layer1, layer2))\n",
    "#     return G\n",
    "\n",
    "\n",
    "# G = multilayered_graph(*subset_sizes)\n",
    "# color = [subset_color[data[\"layer\"]] for v, data in G.nodes(data=True)]\n",
    "# pos = nx.multipartite_layout(G, subset_key=\"layer\")\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# nx.draw(G, pos, node_color=color, with_labels=False)\n",
    "# plt.axis(\"equal\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# import itertools\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from matplotlib.patches import FancyArrowPatch\n",
    "\n",
    "# # Taille des sous-ensembles (couches)\n",
    "# subset_sizes = [3, 2, 3]\n",
    "\n",
    "# # Couleurs pour les nœuds de chaque couche\n",
    "# subset_color = [\n",
    "#     \"gold\",\n",
    "#     \"violet\",\n",
    "#     \"violet\",\n",
    "#     \"violet\",\n",
    "#     \"violet\",\n",
    "#     \"limegreen\",\n",
    "#     \"limegreen\",\n",
    "#     \"darkorange\",\n",
    "# ]\n",
    "\n",
    "# def multilayered_graph(*subset_sizes):\n",
    "#     # Calcul des intervalles pour chaque couche\n",
    "#     extents = nx.utils.pairwise(itertools.accumulate((0,) + subset_sizes))\n",
    "#     layers = [range(start, end) for start, end in extents]\n",
    "#     G = nx.DiGraph()  # Utilisation d'un graphe orienté pour représenter les boucles\n",
    "#     for i, layer in enumerate(layers):\n",
    "#         G.add_nodes_from(layer, layer=i)\n",
    "#         node_list = list(layer)\n",
    "#         # Ajout des arêtes entre tous les nœuds de la même couche\n",
    "#         for u, v in itertools.permutations(node_list, 2):\n",
    "#             G.add_edge(u, v)\n",
    "#         # Ajout des boucles sur chaque nœud\n",
    "#         for node in layer:\n",
    "#             G.add_edge(node, node)\n",
    "#     # Ajout des arêtes entre les couches adjacentes\n",
    "#     for layer1, layer2 in nx.utils.pairwise(layers):\n",
    "#         G.add_edges_from(itertools.product(layer1, layer2))\n",
    "#     return G\n",
    "\n",
    "# def draw_curved_edges(G, pos, ax):\n",
    "#     # Création d'un dictionnaire pour stocker les arêtes entre les mêmes nœuds\n",
    "#     edge_groups = {}\n",
    "#     for u, v in G.edges():\n",
    "#         if u == v:\n",
    "#             # Boucle sur le même nœud\n",
    "#             key = (u, v)\n",
    "#         elif (v, u) in edge_groups:\n",
    "#             # Arête existante dans l'autre sens\n",
    "#             key = (v, u)\n",
    "#         else:\n",
    "#             key = (u, v)\n",
    "#         edge_groups.setdefault(key, []).append((u, v))\n",
    "    \n",
    "#     for (u, v), edges in edge_groups.items():\n",
    "#         num_edges = len(edges)\n",
    "#         # Définition des courbures pour les arêtes multiples\n",
    "#         if num_edges == 1:\n",
    "#             rad_list = [0.0]\n",
    "#         else:\n",
    "#             rad_list = np.linspace(-0.5, 0.5, num_edges)\n",
    "#         for (edge, rad) in zip(edges, rad_list):\n",
    "#             u, v = edge\n",
    "#             if u == v:\n",
    "#                 # Boucle sur le même nœud avec une courbure fixe\n",
    "#                 rad = 0.3\n",
    "#             elif G.nodes[u]['layer'] == G.nodes[v]['layer']:\n",
    "#                 # Ajustement de la courbure pour les arêtes dans la même couche\n",
    "#                 rad *= 1.5\n",
    "#             else:\n",
    "#                 # Réduction de la courbure pour les arêtes entre couches\n",
    "#                 rad *= 0.1\n",
    "#             # Dessin de l'arête avec la courbure spécifiée\n",
    "#             arrow = FancyArrowPatch(\n",
    "#                 posA=pos[u], posB=pos[v],\n",
    "#                 connectionstyle=f\"arc3,rad={rad}\",\n",
    "#                 arrowstyle='-|>',\n",
    "#                 mutation_scale=10.0,\n",
    "#                 color='gray',\n",
    "#                 linewidth=1.0,\n",
    "#             )\n",
    "#             ax.add_patch(arrow)\n",
    "\n",
    "# G = multilayered_graph(*subset_sizes)\n",
    "# color = [subset_color[data[\"layer\"]] for v, data in G.nodes(data=True)]\n",
    "# pos = nx.multipartite_layout(G, subset_key=\"layer\")\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# nx.draw_networkx_nodes(G, pos, node_color=color, ax=ax)\n",
    "# nx.draw_networkx_labels(G, pos, ax=ax)\n",
    "\n",
    "# # Dessin des arêtes avec des courbes individuelles\n",
    "# draw_curved_edges(G, pos, ax)\n",
    "\n",
    "# plt.axis(\"equal\")\n",
    "# plt.axis('off')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.state_dict()\n",
    "# model.weight_ih_l*   e.g. model.weight_ih_l0\n",
    "# model.weight_hh_l*   e.g. model.weight_hh_l0\n",
    "# model.bias_ih_l*   e.g. model.bias_ih_l0\n",
    "# model.bias_hh_l*   e.g. model.bias_hh_l0\n",
    "#\n",
    "# model.all_weights\n",
    "# model.hidden_size\n",
    "# model.input_size\n",
    "#\n",
    "# list(model.parameters())\n",
    "# model.get_expected_hidden_size()\n",
    "# model.get_parameter()\n",
    "#\n",
    "# print(\"model.weight_hh_l0:\", model.weight_hh_l0)\n",
    "# print(\"model.weight_ih_l0:\", model.weight_ih_l0)\n",
    "# print(\"model.bias_ih_l0:\", model.bias_ih_l0)\n",
    "# print(\"model.bias_hh_l0:\", model.bias_hh_l0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One feature, one unit, one layer, no bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"assets/RNN1.drawio.svg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(\n",
    "    input_size=1,  # number of features in the input x\n",
    "    hidden_size=1, # number of neurons in hidden layers\n",
    "    num_layers=1,  # number of recurrent layers\n",
    "    bias=False     # use bias?\n",
    ")\n",
    "model.state_dict() # print the weights and biases of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 1)    # (seq_len, input_size)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.zeros(model.num_layers, model.hidden_size)   # hidden state at time step 0 (initial hidden state), zeros by default\n",
    "h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, hn = model(x, h0)\n",
    "print(f\"The hidden state at each time step:\\ny = \\n{ y }\\n\\n\")\n",
    "print(f\"The hidden state of layer at the final time step:\\nhn = \\n{ hn }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive detailed computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the forward computation in a (naive) detailed way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.nn.functional.tanh\n",
    "\n",
    "x_1 = x[0,0]   # input for time step 1\n",
    "x_2 = x[1,0]   # input for time step 2\n",
    "x_3 = x[2,0]   # input for time step 3\n",
    "\n",
    "h1 = f(x_1 * model.weight_ih_l0 + h0 * model.weight_hh_l0)   # hidden state at time step 1\n",
    "h2 = f(x_2 * model.weight_ih_l0 + h1 * model.weight_hh_l0)   # hidden state at time step 2\n",
    "h3 = f(x_3 * model.weight_ih_l0 + h2 * model.weight_hh_l0)   # hidden state at time step 3\n",
    "\n",
    "print(f\"Output for time step 1:\\nh1 = \\n{ h1 }\\n\\n\")\n",
    "print(f\"Output for time step 2:\\nh2 = \\n{ h2 }\\n\\n\")\n",
    "print(f\"Output for time step 3:\\nh3 = \\n{ h3 }\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algebraic computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rewrite the forward computation in a less naive way (using linear algebra)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{h_t} = \\tanh(\\boldsymbol{x_t} \\boldsymbol{W^{\\top}_{ih}} + \\boldsymbol{h_{t-1}} \\boldsymbol{W^{\\top}_{hh}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.nn.functional.tanh\n",
    "\n",
    "h1 = f(x[0] @ model.weight_ih_l0 + h0 @ model.weight_hh_l0)   # hidden state at time step 1\n",
    "h2 = f(x[1] @ model.weight_ih_l0 + h1 @ model.weight_hh_l0)   # hidden state at time step 2\n",
    "h3 = f(x[2] @ model.weight_ih_l0 + h2 @ model.weight_hh_l0)   # hidden state at time step 3\n",
    "\n",
    "print(f\"Output for time step 1:\\nh1 = \\n{ h1 }\\n\\n\")\n",
    "print(f\"Output for time step 2:\\nh2 = \\n{ h2 }\\n\\n\")\n",
    "print(f\"Output for time step 3:\\nh3 = \\n{ h3 }\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One feature, one unit, one layer, bias **[TODO]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"assets/RNN2.drawio.svg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=1, hidden_size=1, num_layers=1, bias=True)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn(10, 1, 1)    # (seq_len=10, batch_size=1, input_size=1)\n",
    "x = torch.randn(3, 1)    # (seq_len=3, input_size=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, hn = model(x)\n",
    "print(f\"y: {y}\")\n",
    "print(f\"hn: {hn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive detailed computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.nn.functional.tanh(model.weight_ih_l0 * x[0,0] + model.bias_ih_l0 + model.bias_hh_l0)\n",
    "h1 = torch.nn.functional.tanh(model.weight_ih_l0 * x[1,0] + model.weight_hh_l0 * h0 + model.bias_ih_l0 + model.bias_hh_l0)\n",
    "h2 = torch.nn.functional.tanh(model.weight_ih_l0 * x[2,0] + model.weight_hh_l0 * h1 + model.bias_ih_l0 + model.bias_hh_l0)\n",
    "\n",
    "print(f\"h0: { h0 }\\nh1: { h1 }\\nh2: { h2 }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algebraic computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{h_t} = \\tanh(\n",
    "    \\boldsymbol{x_t} \\boldsymbol{W^{\\top}_{ih}}\n",
    "    + \\boldsymbol{b_{ih}}\n",
    "    + \\boldsymbol{h_{t-1}} \\boldsymbol{W^{\\top}_{hh}}\n",
    "    + \\boldsymbol{b_{hh}}\n",
    ")\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.nn.functional.tanh(model.weight_ih_l0 @ x[0] + model.bias_ih_l0 + model.bias_hh_l0)\n",
    "h1 = torch.nn.functional.tanh(model.weight_ih_l0 @ x[1] + model.weight_hh_l0 @ h0 + model.bias_ih_l0 + model.bias_hh_l0)\n",
    "h2 = torch.nn.functional.tanh(model.weight_ih_l0 @ x[2] + model.weight_hh_l0 @ h1 + model.bias_ih_l0 + model.bias_hh_l0)\n",
    "\n",
    "print(f\"h0: { h0 }\\nh1: { h1 }\\nh2: { h2 }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three features, one unit, one layer, no bias **[TODO]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/RNN3.drawio.svg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=3, hidden_size=1, num_layers=1, bias=False)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three features, one unit, one layer, bias **[TODO]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=3, hidden_size=1, num_layers=1, bias=False)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One feature, two units, one layer, no bias **[TODO]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=1, hidden_size=2, num_layers=1, bias=False)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One feature, two units, one layer, bias **[TODO]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=1, hidden_size=2, num_layers=1, bias=True)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three features, two units, one layer, no bias **[TODO]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/RNN4.drawio.svg\" />\n",
    "<br>\n",
    "<img src=\"assets/rnn_matrix.drawio.svg\" />\n",
    "\n",
    "$$\n",
    "\\boldsymbol{h_t} = f(\n",
    "\\color{red}{\\boldsymbol{W^{\\top}_{ih}}} \\color{green}{\\boldsymbol{x_t}}\n",
    "+ \\color{orange}{\\boldsymbol{W^{\\top}_{hh}}} \\boldsymbol{h_{t-1}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=3, hidden_size=2, num_layers=1, bias=False)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn(10, 1, 3)    # (seq_len=10, batch_size=1, input_size=3)\n",
    "x = torch.randn(4, 3)    # (seq_len=3, input_size=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, hn = model(x)\n",
    "print(f\"y: {y}\")\n",
    "print(f\"hn: {hn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive detailed computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0_0 = torch.nn.functional.tanh(model.weight_ih_l0[0,0] * x[0,0] + model.weight_ih_l0[0,1] * x[0,1] + model.weight_ih_l0[0,2] * x[0,2])\n",
    "h0_1 = torch.nn.functional.tanh(model.weight_ih_l0[1,0] * x[0,0] + model.weight_ih_l0[1,1] * x[0,1] + model.weight_ih_l0[1,2] * x[0,2])\n",
    "\n",
    "h1_0 = torch.nn.functional.tanh(model.weight_ih_l0[0,0] * x[1,0] + model.weight_ih_l0[0,1] * x[1,1] + model.weight_ih_l0[0,2] * x[1,2] + model.weight_hh_l0[0,0] * h0_0 + model.weight_hh_l0[0,1] * h0_1)\n",
    "h1_1 = torch.nn.functional.tanh(model.weight_ih_l0[1,0] * x[1,0] + model.weight_ih_l0[1,1] * x[1,1] + model.weight_ih_l0[1,2] * x[1,2] + model.weight_hh_l0[1,0] * h0_0 + model.weight_hh_l0[1,1] * h0_1)\n",
    "\n",
    "h2_0 = torch.nn.functional.tanh(model.weight_ih_l0[0,0] * x[2,0] + model.weight_ih_l0[0,1] * x[2,1] + model.weight_ih_l0[0,2] * x[2,2] + model.weight_hh_l0[0,0] * h1_0 + model.weight_hh_l0[0,1] * h1_1)\n",
    "h2_1 = torch.nn.functional.tanh(model.weight_ih_l0[1,0] * x[2,0] + model.weight_ih_l0[1,1] * x[2,1] + model.weight_ih_l0[1,2] * x[2,2] + model.weight_hh_l0[1,0] * h1_0 + model.weight_hh_l0[1,1] * h1_1)\n",
    "\n",
    "h3_0 = torch.nn.functional.tanh(model.weight_ih_l0[0,0] * x[3,0] + model.weight_ih_l0[0,1] * x[3,1] + model.weight_ih_l0[0,2] * x[3,2] + model.weight_hh_l0[0,0] * h2_0 + model.weight_hh_l0[0,1] * h2_1)\n",
    "h3_1 = torch.nn.functional.tanh(model.weight_ih_l0[1,0] * x[3,0] + model.weight_ih_l0[1,1] * x[3,1] + model.weight_ih_l0[1,2] * x[3,2] + model.weight_hh_l0[1,0] * h2_0 + model.weight_hh_l0[1,1] * h2_1)\n",
    "\n",
    "print(f\"h0: ({ h0_0 }, { h0_1 })\\nh1: ({ h1_0 }, { h1_1 })\\nh2: ({ h2_0 }, { h2_1 })\\nh3: ({ h3_0 }, { h3_1 })\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algebraic computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.nn.functional.tanh(model.weight_ih_l0 @ x[0])\n",
    "h1 = torch.nn.functional.tanh(model.weight_ih_l0 @ x[1] + model.weight_hh_l0 @ h0)\n",
    "h2 = torch.nn.functional.tanh(model.weight_ih_l0 @ x[2] + model.weight_hh_l0 @ h1)\n",
    "h3 = torch.nn.functional.tanh(model.weight_ih_l0 @ x[3] + model.weight_hh_l0 @ h2)\n",
    "\n",
    "print(f\"h0: { h0 }\\nh1: { h1 }\\nh2: { h2 }\\nh3: { h3 }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three features, two units, one layer, bias **[TODO]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"assets/RNN4b.drawio.svg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=3, hidden_size=2, num_layers=1, bias=True)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn(10, 1, 3)    # (seq_len=10, batch_size=1, input_size=3)\n",
    "x = torch.randn(4, 3)    # (seq_len=3, input_size=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, hn = model(x)\n",
    "print(f\"y: {y}\")\n",
    "print(f\"hn: {hn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive detailed computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0_0 = torch.nn.functional.tanh(model.weight_ih_l0[0,0] * x[0,0] + model.weight_ih_l0[0,1] * x[0,1] + model.weight_ih_l0[0,2] * x[0,2] + model.bias_ih_l0[0] + model.bias_hh_l0[0])\n",
    "h0_1 = torch.nn.functional.tanh(model.weight_ih_l0[1,0] * x[0,0] + model.weight_ih_l0[1,1] * x[0,1] + model.weight_ih_l0[1,2] * x[0,2] + model.bias_ih_l0[1] + model.bias_hh_l0[1])\n",
    "\n",
    "h1_0 = torch.nn.functional.tanh(model.weight_ih_l0[0,0] * x[1,0] + model.weight_ih_l0[0,1] * x[1,1] + model.weight_ih_l0[0,2] * x[1,2] + model.weight_hh_l0[0,0] * h0_0 + model.weight_hh_l0[0,1] * h0_1 + model.bias_ih_l0[0] + model.bias_hh_l0[0])\n",
    "h1_1 = torch.nn.functional.tanh(model.weight_ih_l0[1,0] * x[1,0] + model.weight_ih_l0[1,1] * x[1,1] + model.weight_ih_l0[1,2] * x[1,2] + model.weight_hh_l0[1,0] * h0_0 + model.weight_hh_l0[1,1] * h0_1 + model.bias_ih_l0[1] + model.bias_hh_l0[1])\n",
    "\n",
    "h2_0 = torch.nn.functional.tanh(model.weight_ih_l0[0,0] * x[2,0] + model.weight_ih_l0[0,1] * x[2,1] + model.weight_ih_l0[0,2] * x[2,2] + model.weight_hh_l0[0,0] * h1_0 + model.weight_hh_l0[0,1] * h1_1 + model.bias_ih_l0[0] + model.bias_hh_l0[0])\n",
    "h2_1 = torch.nn.functional.tanh(model.weight_ih_l0[1,0] * x[2,0] + model.weight_ih_l0[1,1] * x[2,1] + model.weight_ih_l0[1,2] * x[2,2] + model.weight_hh_l0[1,0] * h1_0 + model.weight_hh_l0[1,1] * h1_1 + model.bias_ih_l0[1] + model.bias_hh_l0[1])\n",
    "\n",
    "h3_0 = torch.nn.functional.tanh(model.weight_ih_l0[0,0] * x[3,0] + model.weight_ih_l0[0,1] * x[3,1] + model.weight_ih_l0[0,2] * x[3,2] + model.weight_hh_l0[0,0] * h2_0 + model.weight_hh_l0[0,1] * h2_1 + model.bias_ih_l0[0] + model.bias_hh_l0[0])\n",
    "h3_1 = torch.nn.functional.tanh(model.weight_ih_l0[1,0] * x[3,0] + model.weight_ih_l0[1,1] * x[3,1] + model.weight_ih_l0[1,2] * x[3,2] + model.weight_hh_l0[1,0] * h2_0 + model.weight_hh_l0[1,1] * h2_1 + model.bias_ih_l0[1] + model.bias_hh_l0[1])\n",
    "\n",
    "print(f\"h0: ({ h0_0 }, { h0_1 })\\nh1: ({ h1_0 }, { h1_1 })\\nh2: ({ h2_0 }, { h2_1 })\\nh3: ({ h3_0 }, { h3_1 })\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algebraic computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.nn.functional.tanh(model.weight_ih_l0 @ x[0] + model.bias_ih_l0 + model.bias_hh_l0)\n",
    "h1 = torch.nn.functional.tanh(model.weight_ih_l0 @ x[1] + model.weight_hh_l0 @ h0 + model.bias_ih_l0 + model.bias_hh_l0)\n",
    "h2 = torch.nn.functional.tanh(model.weight_ih_l0 @ x[2] + model.weight_hh_l0 @ h1 + model.bias_ih_l0 + model.bias_hh_l0)\n",
    "h3 = torch.nn.functional.tanh(model.weight_ih_l0 @ x[3] + model.weight_hh_l0 @ h2 + model.bias_ih_l0 + model.bias_hh_l0)\n",
    "\n",
    "print(f\"h0: { h0 }\\nh1: { h1 }\\nh2: { h2 }\\nh3: { h3 }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One feature, one unit, two layers (stacked RNN), no bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(\n",
    "    input_size=1,  # number of features in the input x\n",
    "    hidden_size=1, # number of neurons in hidden layers\n",
    "    num_layers=2,  # number of recurrent layers\n",
    "    bias=False     # use bias?\n",
    ")\n",
    "model.state_dict() # print the weights and biases of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 1)    # (seq_len, input_size)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.zeros(model.num_layers, model.hidden_size)   # hidden state at time step 0 (initial hidden state), zeros by default\n",
    "h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, hn = model(x, h0)\n",
    "print(f\"The hidden state at each time step:\\ny = \\n{ y }\\n\\n\")\n",
    "print(f\"The hidden state of layer at the final time step:\\nhn = \\n{ hn }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward pseudo code:\n",
    "\n",
    "```python\n",
    "def forward(x, h_0=None):\n",
    "    h_t_minus_1 = h_0\n",
    "    h_t = h_0\n",
    "    output = []\n",
    "    for t in range(seq_len):\n",
    "\n",
    "        input_t = x[t]\n",
    "        for layer in range(num_layers):\n",
    "            h_t[layer] = torch.tanh(\n",
    "                input_t @ weight_ih[layer].T\n",
    "                + h_t_minus_1[layer] @ weight_hh[layer].T\n",
    "            )\n",
    "            input_t = h_t[layer]    # The output of the current layer is the input of the next layer\n",
    "\n",
    "        output.append(h_t[-1])\n",
    "        h_t_minus_1 = h_t\n",
    "\n",
    "    output = torch.stack(output)\n",
    "    return output, h_t\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive detailed computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the forward computation in a (naive) detailed way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.nn.functional.tanh\n",
    "\n",
    "x_1 = x[0,0]   # input for time step 1\n",
    "x_2 = x[1,0]   # input for time step 2\n",
    "x_3 = x[2,0]   # input for time step 3\n",
    "\n",
    "h0_l0 = h0[0,0]   # hidden state at time step 0 for layer 0\n",
    "h0_l1 = h0[1,0]   # hidden state at time step 0 for layer 1\n",
    "\n",
    "# Hidden state at time step 1\n",
    "h1_l0 = f(  x_1 * model.weight_ih_l0 + h0_l0 * model.weight_hh_l0)\n",
    "h1_l1 = f(h1_l0 * model.weight_ih_l1 + h0_l1 * model.weight_hh_l1)\n",
    "h1 = torch.tensor([[h1_l0], [h1_l1]])\n",
    "\n",
    "# Hidden state at time step 2\n",
    "h2_l0 = f(  x_2 * model.weight_ih_l0 + h1_l0 * model.weight_hh_l0)\n",
    "h2_l1 = f(h2_l0 * model.weight_ih_l1 + h1_l1 * model.weight_hh_l1)\n",
    "h2 = torch.tensor([[h2_l0], [h2_l1]])\n",
    "\n",
    "# Hidden state at time step 3\n",
    "h3_l0 = f(  x_3 * model.weight_ih_l0 + h2_l0 * model.weight_hh_l0)\n",
    "h3_l1 = f(h3_l0 * model.weight_ih_l1 + h2_l1 * model.weight_hh_l1)\n",
    "h3 = torch.tensor([[h3_l0], [h3_l1]])\n",
    "\n",
    "print(f\"Output for time step 1:\\nh1 = \\n{ h1 }\\n\\n\")\n",
    "print(f\"Output for time step 2:\\nh2 = \\n{ h2 }\\n\\n\")\n",
    "print(f\"Output for time step 3:\\nh3 = \\n{ h3 }\\n\\n\")\n",
    "\n",
    "print(f\"The hidden state at each time step:\\ny = \\n{ torch.tensor([h1_l1, h2_l1, h3_l1]).unsqueeze(1) }\\n\\n\")\n",
    "print(f\"The hidden state of layer at the final time step:\\nhn = \\n{ h3 }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algebraic computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rewrite the forward computation in a less naive way (using linear algebra)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First layer ($l = 0$):\n",
    "$$\n",
    "\\boldsymbol{h}^{(0)}_t = \\tanh\\left( \\boldsymbol{x}_t \\boldsymbol{W}^{(0)}_{ih} + \\boldsymbol{h}^{(0)}_{t-1} \\boldsymbol{W}^{(0)}_{hh} \\right)\n",
    "$$\n",
    "\n",
    "- Next layers ($l \\geq 1$):\n",
    "$$\n",
    "\\boldsymbol{h}^{(l)}_t = \\tanh\\left(\\boldsymbol{h}^{(l-1)}_t \\boldsymbol{W}^{(l)}_{ih} + \\boldsymbol{h}^{(l)}_{t-1} \\boldsymbol{W}^{(l)}_{hh} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.nn.functional.tanh\n",
    "\n",
    "# Time step 1 (h1)\n",
    "h1_l0 = f( x[0] @ model.weight_ih_l0 + h0[0] @ model.weight_hh_l0)\n",
    "h1_l1 = f(h1_l0 @ model.weight_ih_l1 + h0[1] @ model.weight_hh_l1)\n",
    "h1 = torch.stack([h1_l0, h1_l1])\n",
    "\n",
    "# Time step 2 (h2)\n",
    "h2_l0 = f( x[1] @ model.weight_ih_l0 + h1[0] @ model.weight_hh_l0)\n",
    "h2_l1 = f(h2_l0 @ model.weight_ih_l1 + h1[1] @ model.weight_hh_l1)\n",
    "h2 = torch.stack([h2_l0, h2_l1])\n",
    "\n",
    "# Time step 3 (h3)\n",
    "h3_l0 = f( x[2] @ model.weight_ih_l0 + h2[0] @ model.weight_hh_l0)\n",
    "h3_l1 = f(h3_l0 @ model.weight_ih_l1 + h2[1] @ model.weight_hh_l1)\n",
    "h3 = torch.stack([h3_l0, h3_l1])\n",
    "\n",
    "print(f\"Output for time step 1:\\nh1 = \\n{ h1 }\\n\\n\")\n",
    "print(f\"Output for time step 2:\\nh2 = \\n{ h2 }\\n\\n\")\n",
    "print(f\"Output for time step 3:\\nh3 = \\n{ h3 }\\n\\n\")\n",
    "\n",
    "print(f\"The hidden state at each time step:\\ny = \\n{ torch.tensor([h1_l1, h2_l1, h3_l1]).unsqueeze(1) }\\n\\n\")\n",
    "print(f\"The hidden state of layers at the final time step:\\nhn = \\n{ h3 }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three features, two units, two layers (stacked RNN), no bias **[TODO]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/RNN5.drawio.svg\" />\n",
    "<br>\n",
    "<img src=\"assets/stacked_rnn_matrix.drawio.svg\" />\n",
    "\n",
    "- First layer ($l = 0$):\n",
    "$$\n",
    "\\Large\n",
    "\\boldsymbol{h}^{(0)}_t = f\\left( \\boldsymbol{W}^{(0)\\top}_{ih} \\boldsymbol{x}_t + \\boldsymbol{W}^{(0)\\top}_{hh} \\boldsymbol{h}^{(0)}_{t-1} \\right)\n",
    "$$\n",
    "\n",
    "- Next layers ($l \\geq 1$):\n",
    "$$\n",
    "\\Large\n",
    "\\boldsymbol{h}^{(l)}_t = f\\left(\\boldsymbol{W}^{(l)\\top}_{ih} \\boldsymbol{h}^{(l\\color{red}{-1})}_{\\color{red}{t}} + \\boldsymbol{W}^{(l)\\top}_{hh} \\boldsymbol{h}^{(l)}_{t\\color{red}{-1}} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=3, hidden_size=2, num_layers=2, bias=False)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 1, 3)    # (seq_len=10, batch_size=1, input_size=3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three features, two units, four layers (stacked RNN), no bias **[TODO]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"assets/RNN6.drawio.svg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=3, hidden_size=2, num_layers=4, bias=False)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One feature, one unit, one layer, no bias, bidirectionnal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(\n",
    "    input_size=1,       # number of features in the input x\n",
    "    hidden_size=1,      # number of neurons in hidden layers\n",
    "    num_layers=1,       # number of recurrent layers\n",
    "    bias=False,         # don't use bias\n",
    "    bidirectional=True  # bidirectional RNN\n",
    ")\n",
    "model.state_dict()      # print the weights and biases of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 1)    # (seq_len, input_size)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_directions = 2 if model.bidirectional else 1\n",
    "\n",
    "h0 = torch.zeros(model.num_layers * num_directions, model.hidden_size)   # hidden state at time step 0 (initial hidden state), zeros by default\n",
    "h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, hn = model(x, h0)\n",
    "print(f\"y (hidden states at each time step):\\ny = \\n{ y }\\n\\n\")\n",
    "print(f\"hn (final hidden states):\\nhn = \\n{ hn }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive detailed computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the forward computation in a (naive) detailed way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.nn.functional.tanh\n",
    "\n",
    "x_1 = x[0,0]   # input for time step 1\n",
    "x_2 = x[1,0]   # input for time step 2\n",
    "x_3 = x[2,0]   # input for time step 3\n",
    "\n",
    "# Forward weights\n",
    "W_ih_f = model.weight_ih_l0      # shape (hidden_size, input_size)\n",
    "W_hh_f = model.weight_hh_l0      # shape (hidden_size, hidden_size)\n",
    "\n",
    "# Backward weights\n",
    "W_ih_b = model.weight_ih_l0_reverse\n",
    "W_hh_b = model.weight_hh_l0_reverse\n",
    "\n",
    "# Extract initial forward and backward hidden states\n",
    "h0_f = h0[0]  # forward initial hidden state\n",
    "h0_b = h0[1]  # backward initial hidden state\n",
    "\n",
    "# Forward computation over time\n",
    "h1_f = f(x_1 * W_ih_f + h0_f * W_hh_f)\n",
    "h2_f = f(x_2 * W_ih_f + h1_f * W_hh_f)\n",
    "h3_f = f(x_3 * W_ih_f + h2_f * W_hh_f)\n",
    "\n",
    "# Backward computation (reverse time order)\n",
    "# Start from the end (x[2]) with h0_b\n",
    "h1_b = f(x_3 * W_ih_b + h0_b * W_hh_b)\n",
    "h2_b = f(x_2 * W_ih_b + h1_b * W_hh_b)\n",
    "h3_b = f(x_1 * W_ih_b + h2_b * W_hh_b)\n",
    "\n",
    "# The output at time t is the concatenation of the forward state at t\n",
    "# and the backward state at (seq_len - t - 1).\n",
    "y = torch.tensor([\n",
    "    [h1_f, h3_b],  # at t=0, forward is h1_f, backward is h3_b (from end)\n",
    "    [h2_f, h2_b],  # at t=1, forward is h2_f, backward is h2_b\n",
    "    [h3_f, h1_b]   # at t=2, forward is h3_f, backward is h1_b (from start)\n",
    "])\n",
    "\n",
    "# The final hidden state hn consists of the last forward state (h3_f)\n",
    "# and the first backward state computed (h1_b).\n",
    "hn = torch.tensor([[h3_f], [h1_b]])\n",
    "\n",
    "print(f\"y (hidden states at each time step):\\ny = \\n{ y }\\n\\n\")\n",
    "print(f\"hn (final hidden states):\\nhn = \\n{ hn }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algebraic computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rewrite the forward computation in a less naive way (using linear algebra)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Direction forward ($\\color{red}{\\text{from } t=1 \\text{ to } t=T}$) :\n",
    "\n",
    "$$\n",
    "\\boldsymbol{h}_t^{(f)} = \\tanh\\left( \\boldsymbol{x}_t \\boldsymbol{W}_{ih}^{(f)} + \\boldsymbol{h}_{t-1}^{(f)} \\boldsymbol{W}_{hh}^{(f)} \\right), \\quad\\quad \\text{with } \\boldsymbol{h}_0^{(f)} = \\boldsymbol{0}\n",
    "$$\n",
    "\n",
    "- Direction backward ($\\color{red}{\\text{from } t=T \\text{ to } t=1}$) :\n",
    "\n",
    "$$\n",
    "\\boldsymbol{h}_t^{(b)} = \\tanh\\left( \\boldsymbol{x}_t \\boldsymbol{W}_{ih}^{(b)} + \\boldsymbol{h}_{t+1}^{(b)} \\boldsymbol{W}_{hh}^{(b)} \\right), \\quad\\quad \\text{with } \\boldsymbol{h}_{T+1}^{(b)} = \\boldsymbol{0}\n",
    "$$\n",
    "\n",
    "The representation of the bidirectional hidden state at time t is then the concatenation of the two:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{h}_t = \n",
    "\\begin{bmatrix}\n",
    "\\boldsymbol{h}_t^{(f)} \\\\\n",
    "\\boldsymbol{h}_t^{(b)}\n",
    "\\end{bmatrix}^{\\top}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.nn.functional.tanh\n",
    "\n",
    "# Forward weights\n",
    "W_ih_f = model.weight_ih_l0      # shape (hidden_size, input_size)\n",
    "W_hh_f = model.weight_hh_l0      # shape (hidden_size, hidden_size)\n",
    "\n",
    "# Backward weights\n",
    "W_ih_b = model.weight_ih_l0_reverse\n",
    "W_hh_b = model.weight_hh_l0_reverse\n",
    "\n",
    "# Extract initial forward and backward hidden states\n",
    "h0_f = h0[0]  # forward initial hidden state\n",
    "h0_b = h0[1]  # backward initial hidden state\n",
    "\n",
    "# Forward computation over time\n",
    "h1_f = f(x[0] @ W_ih_f.T + h0_f @ W_hh_f.T)\n",
    "h2_f = f(x[1] @ W_ih_f.T + h1_f @ W_hh_f.T)\n",
    "h3_f = f(x[2] @ W_ih_f.T + h2_f @ W_hh_f.T)\n",
    "\n",
    "# Backward computation (reverse time order)\n",
    "# Start from the end (x[2]) with h0_b\n",
    "h1_b = f(x[2] @ W_ih_b.T + h0_b @ W_hh_b.T)\n",
    "h2_b = f(x[1] @ W_ih_b.T + h1_b @ W_hh_b.T)\n",
    "h3_b = f(x[0] @ W_ih_b.T + h2_b @ W_hh_b.T)\n",
    "\n",
    "# The output at time t is the concatenation of the forward state at t\n",
    "# and the backward state at (seq_len - t - 1).\n",
    "y = torch.tensor([\n",
    "    [h1_f, h3_b],  # at t=0, forward is h1_f, backward is h3_b (from end)\n",
    "    [h2_f, h2_b],  # at t=1, forward is h2_f, backward is h2_b\n",
    "    [h3_f, h1_b]   # at t=2, forward is h3_f, backward is h1_b (from start)\n",
    "])\n",
    "\n",
    "# The final hidden state hn consists of the last forward state (h3_f)\n",
    "# and the first backward state computed (h1_b).\n",
    "hn = torch.tensor([[h3_f], [h1_b]])\n",
    "\n",
    "print(f\"y (hidden states at each time step):\\ny = \\n{ y }\\n\\n\")\n",
    "print(f\"hn (final hidden states):\\nhn = \\n{ hn }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One feature, one unit, one layer, bias, bidirectionnal **[TODO]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=1, hidden_size=1, num_layers=1, bias=True, bidirectional=True)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward pseudo code (see https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN):\n",
    "\n",
    "```python\n",
    "def forward(x, h_0=None):\n",
    "    h_t_minus_1 = h_0\n",
    "    h_t = h_0\n",
    "    output = []\n",
    "    for t in range(seq_len):\n",
    "\n",
    "        for layer in range(num_layers):\n",
    "            h_t[layer] = torch.tanh(\n",
    "                x[t] @ weight_ih[layer].T\n",
    "                + bias_ih[layer]\n",
    "                + h_t_minus_1[layer] @ weight_hh[layer].T\n",
    "                + bias_hh[layer]\n",
    "            )\n",
    "        output.append(h_t[-1])\n",
    "        h_t_minus_1 = h_t\n",
    "\n",
    "    output = torch.stack(output)\n",
    "    return output, h_t\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One feature, one unit, one layer, no bias **[TODO]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(\n",
    "    input_size=1,  # number of features in the input x\n",
    "    hidden_size=1, # number of neurons in hidden layers\n",
    "    num_layers=1,  # number of recurrent layers\n",
    "    bias=False     # use bias?\n",
    ")\n",
    "model.state_dict() # print the weights and biases of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One feature, one unit, one layer, bias **[TODO]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(\n",
    "    input_size=1,\n",
    "    hidden_size=1,\n",
    "    num_layers=1,\n",
    "    bias=True\n",
    ")\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three features, one unit, one layer, no bias **[TODO]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(\n",
    "    input_size=3,\n",
    "    hidden_size=1,\n",
    "    num_layers=1,\n",
    "    bias=False\n",
    ")\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three features, two units, one layer, no bias **[TODO]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(\n",
    "    input_size=3,\n",
    "    hidden_size=2,\n",
    "    num_layers=1,\n",
    "    bias=False\n",
    ")\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three features, two units, one layer, bias **[TODO]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(\n",
    "    input_size=3,\n",
    "    hidden_size=2,\n",
    "    num_layers=1,\n",
    "    bias=True\n",
    ")\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three features, two units, two layers (stacked RNN), no bias **[TODO]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(\n",
    "    input_size=3,\n",
    "    hidden_size=2,\n",
    "    num_layers=2,\n",
    "    bias=False\n",
    ")\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One feature, one unit, one layer, no bias, bidirectionnal **[TODO]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(\n",
    "    input_size=1,\n",
    "    hidden_size=1,\n",
    "    num_layers=1,\n",
    "    bias=False,\n",
    "    bidirectional=True\n",
    ")\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One feature, one unit, one layer, no bias **[TODO]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU(\n",
    "    input_size=1,  # number of features in the input x\n",
    "    hidden_size=1, # number of neurons in hidden layers\n",
    "    num_layers=1,  # number of recurrent layers\n",
    "    bias=False     # use bias?\n",
    ")\n",
    "model.state_dict() # print the weights and biases of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One feature, one unit, one layer, bias **[TODO]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU(\n",
    "    input_size=1,\n",
    "    hidden_size=1,\n",
    "    num_layers=1,\n",
    "    bias=True\n",
    ")\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three features, one unit, one layer, no bias **[TODO]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU(\n",
    "    input_size=3,\n",
    "    hidden_size=1,\n",
    "    num_layers=1,\n",
    "    bias=False\n",
    ")\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three features, two units, one layer, no bias **[TODO]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU(\n",
    "    input_size=3,\n",
    "    hidden_size=2,\n",
    "    num_layers=1,\n",
    "    bias=False\n",
    ")\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three features, two units, one layer, bias **[TODO]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU(\n",
    "    input_size=3,\n",
    "    hidden_size=2,\n",
    "    num_layers=1,\n",
    "    bias=True\n",
    ")\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three features, two units, two layers (stacked RNN), no bias **[TODO]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU(\n",
    "    input_size=3,\n",
    "    hidden_size=2,\n",
    "    num_layers=2,\n",
    "    bias=False\n",
    ")\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One feature, one unit, one layer, no bias, bidirectionnal **[TODO]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU(\n",
    "    input_size=1,\n",
    "    hidden_size=1,\n",
    "    num_layers=1,\n",
    "    bias=False,\n",
    "    bidirectional=True\n",
    ")\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parameters:\", len(torch.nn.utils.parameters_to_vector(model.parameters())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
