{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep dive into backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://github.com/jeremiedecock/neural-network-figures.git\n",
    "import nnfigs.core as nnfig\n",
    "import numpy as np\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\renewcommand{\\cur}{i}\n",
    "\\renewcommand{\\prev}{j}\n",
    "\\renewcommand{\\prevcur}{{\\cur\\prev}}\n",
    "\\renewcommand{\\next}{k}\n",
    "\\renewcommand{\\curnext}{{\\next\\cur}}\n",
    "\\renewcommand{\\ex}{\\eta}\n",
    "\\renewcommand{\\pot}{\\sigma}\n",
    "\\renewcommand{\\feature}{x}\n",
    "\\renewcommand{\\weight}{{\\boldsymbol{w}}}\n",
    "\\renewcommand{\\wcur}{{\\weight_{\\cur\\prev}}}\n",
    "\\renewcommand{\\activthres}{\\theta}\n",
    "\\renewcommand{\\activfunc}{f}\n",
    "\\renewcommand{\\errfunc}{E}\n",
    "\\renewcommand{\\learnrate}{\\epsilon}\n",
    "\\renewcommand{\\learnit}{n}\n",
    "\\renewcommand{\\sigout}{{\\boldsymbol{y}}}\n",
    "\\renewcommand{\\sigoutdes}{{\\boldsymbol{y^*}}}\n",
    "\\renewcommand{\\weights}{\\boldsymbol{W}}\n",
    "\\renewcommand{\\errsig}{\\Delta}\n",
    "$\n",
    "\n",
    "Notations:\n",
    "\n",
    "- $\\cur$: couche courante\n",
    "- $\\prev$: couche immédiatement en amont de la courche courrante (i.e. vers la couche d'entrée du réseau)\n",
    "- $\\next$: couche immédiatement en aval de la courche courrante (i.e. vers la couche de sortie du réseau)\n",
    "- $\\ex$: exemple (*sample* ou *feature*) courant (i.e. le vecteur des entrées courantes du réseau)\n",
    "- $\\pot_\\cur$: *Potentiel d'activation* du neurone $i$ pour l'exemple courant\n",
    "- $\\wcur$: Poids de la connexion entre le neurone $j$ et le neurone $i$\n",
    "- $\\activthres_\\cur$: *Seuil d'activation* du neurone $i$\n",
    "- $\\activfunc_\\cur$: *Fonction d'activation* du neurone $i$\n",
    "- $\\errfunc$: *Fonction objectif* ou *fonction d'erreur*\n",
    "- $\\learnrate$: *Pas d'apprentissage* ou *Taux d'apprentissage*\n",
    "- $\\learnit$: Numéro d'itération (ou cycle ou époque) du processus d'apprentissage\n",
    "- $\\sigout_\\cur$: Signal de sortie du neurone $i$ pour l'exemple courant\n",
    "- $\\sigoutdes_\\cur$: Sortie désirée (*étiquette*) du neurone $i$ pour l'exemple courant\n",
    "- $\\weights$: Matrice des poids du réseau (en réalité il y a une matrice de taille potentiellement différente par couche)\n",
    "- $\\errsig_i$: *Signal d'erreur* du neurone $i$ pour l'exemple courant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STR_CUR = r\"i\"       # Couche courante\n",
    "STR_PREV = r\"j\"      # Couche immédiatement en amont de la courche courrante (i.e. vers la couche d'entrée du réseau)\n",
    "STR_NEXT = r\"k\"      # Couche immédiatement en aval de la courche courrante (i.e. vers la couche de sortie du réseau)\n",
    "STR_EX = r\"\\eta\"     # Exemple (*sample* ou *feature*) courant (i.e. le vecteur des entrées courantes du réseau)\n",
    "STR_POT = r\"\\sigma\"       # *Potentiel d'activation* du neurone $i$ pour l'exemple $\\ex$\n",
    "STR_POT_CUR = r\"x_i\"       # *Potentiel d'activation* du neurone $i$ pour l'exemple $\\ex$\n",
    "STR_WEIGHT = r\"w\"\n",
    "STR_WEIGHT_CUR = r\"w_{ij}\"  # Poids de la connexion entre le neurone $j$ et le neurone $i$\n",
    "STR_ACTIVTHRES = r\"\\theta\"  # *Seuil d'activation* du neurone $i$\n",
    "STR_ACTIVFUNC = r\"f\"        # *Fonction d'activation* du neurone $i$\n",
    "STR_ERRFUNC = r\"E\"          # *Fonction objectif* ou *fonction d'erreur*\n",
    "STR_LEARNRATE = r\"\\epsilon\" # *Pas d'apprentissage* ou *Taux d'apprentissage*\n",
    "STR_LEARNIT = r\"n\"          # Numéro d'itération (ou cycle ou époque) du processus d'apprentissage\n",
    "STR_SIGIN = r\"x\"            # Signal de sortie du neurone $i$ pour l'exemple $\\ex$\n",
    "STR_SIGOUT = r\"y\"           # Signal de sortie du neurone $i$ pour l'exemple $\\ex$\n",
    "STR_SIGOUT_CUR = r\"y_i\"\n",
    "STR_SIGOUT_PREV = r\"y_j\"\n",
    "STR_SIGOUT_DES = r\"d\"           # Sortie désirée (*étiquette*) du neurone $i$ pour l'exemple $\\ex$\n",
    "STR_SIGOUT_DES_CUR = r\"d_i\"\n",
    "STR_WEIGHTS = r\"W\"              # Matrice des poids du réseau (en réalité il y a une matrice de taille potentiellement différente par couche)\n",
    "STR_ERRSIG = r\"\\Delta\"          # *Signal d'erreur* du neurone $i$ pour l'exemple $\\ex$\n",
    "\n",
    "def tex(tex_str):\n",
    "    return r\"$\" + tex_str + r\"$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the model in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**: The model is a simple feedforward neural network with two hidden layers. To simplify computations, we don't use any bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 2, bias=False),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.Linear(2, 2, bias=False),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.Linear(2, 1, bias=False)\n",
    ")\n",
    "model.state_dict() # print the weights and biases of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.randn(1)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = nnfig.init_figure(size_x=8, size_y=4)\n",
    "\n",
    "HSPACE = 6\n",
    "VSPACE = 4\n",
    "\n",
    "# Synapse #####################################\n",
    "\n",
    "# Layer 1-2\n",
    "nnfig.draw_synapse(ax, (0,  VSPACE), (HSPACE,  VSPACE), label=tex(STR_WEIGHT + \"_1\"), label_position=0.4)\n",
    "nnfig.draw_synapse(ax, (0, -VSPACE), (HSPACE,  VSPACE), label=tex(STR_WEIGHT + \"_3\"), label_position=0.25, label_offset_y=-0.8)\n",
    "\n",
    "nnfig.draw_synapse(ax, (0,  VSPACE), (HSPACE, -VSPACE), label=tex(STR_WEIGHT + \"_2\"), label_position=0.25)\n",
    "nnfig.draw_synapse(ax, (0, -VSPACE), (HSPACE, -VSPACE), label=tex(STR_WEIGHT + \"_4\"), label_position=0.4, label_offset_y=-0.8)\n",
    "\n",
    "# Layer 2-3\n",
    "nnfig.draw_synapse(ax, (HSPACE,  VSPACE), (2*HSPACE,  VSPACE), label=tex(STR_WEIGHT + \"_5\"), label_position=0.4)\n",
    "nnfig.draw_synapse(ax, (HSPACE, -VSPACE), (2*HSPACE,  VSPACE), label=tex(STR_WEIGHT + \"_7\"), label_position=0.25, label_offset_y=-0.8)\n",
    "\n",
    "nnfig.draw_synapse(ax, (HSPACE,  VSPACE), (2*HSPACE, -VSPACE), label=tex(STR_WEIGHT + \"_6\"), label_position=0.25)\n",
    "nnfig.draw_synapse(ax, (HSPACE, -VSPACE), (2*HSPACE, -VSPACE), label=tex(STR_WEIGHT + \"_8\"), label_position=0.4, label_offset_y=-0.8)\n",
    "\n",
    "# Layer 3-4\n",
    "nnfig.draw_synapse(ax, (2*HSPACE,  VSPACE), (3*HSPACE, 0), label=tex(STR_WEIGHT + \"_9\"), label_position=0.4)\n",
    "nnfig.draw_synapse(ax, (2*HSPACE, -VSPACE), (3*HSPACE, 0), label=tex(STR_WEIGHT + \"_{10}\"), label_position=0.4, label_offset_y=-0.8)\n",
    "\n",
    "nnfig.draw_synapse(ax, (3*HSPACE, 0), (3*HSPACE + 2, 0))\n",
    "\n",
    "# Neuron ######################################\n",
    "\n",
    "# Layer 1 (input)\n",
    "nnfig.draw_neuron(ax, (0,  VSPACE), 0.5, empty=True)\n",
    "nnfig.draw_neuron(ax, (0, -VSPACE), 0.5, empty=True)\n",
    "\n",
    "# Layer 2\n",
    "nnfig.draw_neuron(ax, (HSPACE,  VSPACE), 1, ag_func=\"sum\", tr_func=\"sigmoid\")\n",
    "nnfig.draw_neuron(ax, (HSPACE, -VSPACE), 1, ag_func=\"sum\", tr_func=\"sigmoid\")\n",
    "\n",
    "# Layer 3\n",
    "nnfig.draw_neuron(ax, (2*HSPACE,  VSPACE), 1, ag_func=\"sum\", tr_func=\"sigmoid\")\n",
    "nnfig.draw_neuron(ax, (2*HSPACE, -VSPACE), 1, ag_func=\"sum\", tr_func=\"sigmoid\")\n",
    "\n",
    "# Layer 4\n",
    "nnfig.draw_neuron(ax, (3*HSPACE, 0), 1, ag_func=\"sum\", tr_func=\"identity\")\n",
    "\n",
    "# Text ########################################\n",
    "\n",
    "# Layer 1 (input)\n",
    "#plt.text(x=0.5, y=VSPACE+1, s=tex(STR_SIGOUT + \"_i\"), fontsize=12)\n",
    "plt.text(x=-1.7, y=VSPACE,      s=tex(STR_SIGIN + \"_1\"), fontsize=12)\n",
    "plt.text(x=-1.7, y=-VSPACE-0.2, s=tex(STR_SIGIN + \"_2\"), fontsize=12)\n",
    "\n",
    "# Layer 2\n",
    "#plt.text(x=HSPACE-1.25, y=VSPACE+1.5, s=tex(STR_POT + \"_1\"), fontsize=12)\n",
    "plt.text(x=HSPACE+0.4,  y=VSPACE+1.5, s=tex(STR_SIGOUT + \"_1\"), fontsize=12)\n",
    "\n",
    "#plt.text(x=HSPACE-1.25, y=-VSPACE-1.8, s=tex(STR_POT + \"_2\"), fontsize=12)\n",
    "plt.text(x=HSPACE+0.4,  y=-VSPACE-1.8, s=tex(STR_SIGOUT + \"_2\"), fontsize=12)\n",
    "\n",
    "# Layer 3\n",
    "#plt.text(x=2*HSPACE-1.25, y=VSPACE+1.5, s=tex(STR_POT + \"_3\"), fontsize=12)\n",
    "plt.text(x=2*HSPACE+0.4,  y=VSPACE+1.5, s=tex(STR_SIGOUT + \"_3\"), fontsize=12)\n",
    "\n",
    "#plt.text(x=2*HSPACE-1.25, y=-VSPACE-1.8, s=tex(STR_POT + \"_4\"), fontsize=12)\n",
    "plt.text(x=2*HSPACE+0.4,  y=-VSPACE-1.8, s=tex(STR_SIGOUT + \"_4\"), fontsize=12)\n",
    "\n",
    "# Layer 4\n",
    "#plt.text(x=3*HSPACE-1.25, y=1.5, s=tex(STR_POT + \"_o\"), fontsize=12)\n",
    "#plt.text(x=3*HSPACE+0.4,  y=1.5, s=tex(STR_SIGOUT + \"_o\"), fontsize=12)\n",
    "\n",
    "plt.text(x=3*HSPACE+2.5,  y=-0.3,\n",
    "         s=tex(STR_SIGOUT),\n",
    "         fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\renewcommand{\\yone}{\\underbrace{\\activfunc \\left(\\weight_1 \\feature_1 + \\weight_3 \\feature_2 \\right)}_{\\sigout_1}}\n",
    "\\renewcommand{\\ytwo}{\\underbrace{\\activfunc \\left(\\weight_2 \\feature_1 + \\weight_4 \\feature_2 \\right)}_{\\sigout_2}}\n",
    "\\renewcommand{\\ythree}{\\underbrace{\\activfunc \\left(\\weight_5 \\yone + \\weight_7 \\ytwo \\right)}_{\\sigout_3}}\n",
    "\\renewcommand{\\yfour}{\\underbrace{\\activfunc \\left(\\weight_6 \\yone + \\weight_8 \\ytwo \\right)}_{\\sigout_4}}\n",
    "$\n",
    "\n",
    "$$\n",
    "\\sigout =\n",
    "\\activfunc \\left(\n",
    "\\weight_9 ~ \\ythree\n",
    "+\n",
    "\\weight_{10} ~ \\yfour\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x[0].item()\n",
    "x2 = x[1].item()\n",
    "\n",
    "w1 = model[0].weight[0, 0].item()\n",
    "w2 = model[0].weight[1, 0].item()\n",
    "w3 = model[0].weight[0, 1].item()\n",
    "w4 = model[0].weight[1, 1].item()\n",
    "\n",
    "w5 = model[2].weight[0, 0].item()\n",
    "w6 = model[2].weight[1, 0].item()\n",
    "w7 = model[2].weight[0, 1].item()\n",
    "w8 = model[2].weight[1, 1].item()\n",
    "\n",
    "w9 = model[4].weight[0, 0].item()\n",
    "w10 = model[4].weight[0, 1].item()\n",
    "\n",
    "# f = torch.nn.functional.tanh\n",
    "f = math.tanh\n",
    "\n",
    "def df(x):\n",
    "    \"\"\"Derivative of the tanh function\n",
    "    $\\tanh '= \\frac{1}{\\cosh^{2}} = 1-\\tanh^{2}$\n",
    "    \"\"\"\n",
    "    y = 1. - math.tanh(x) ** 2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma1 = w1 * x1 + w3 * x2  # (x @ model[0].weight)[0].item()\n",
    "y1 = f(sigma1)              # torch.nn.functional.tanh(x @ model[0].weight)[0]\n",
    "\n",
    "sigma2 = w2 * x1 + w4 * x2  # (x @ model[0].weight)[1]\n",
    "y2 = f(sigma2)              # torch.nn.functional.tanh(x @ model[0].weight)[1]\n",
    "\n",
    "sigma3 = w5 * y1 + w7 * y2  # (torch.nn.functional.tanh(x @ model[0].weight) @ model[2].weight)[0]\n",
    "y3 = f(sigma3)              # torch.nn.functional.tanh(torch.nn.functional.tanh(x @ model[0].weight) @ model[2].weight)[0].item()\n",
    "\n",
    "sigma4 = w6 * y1 + w8 * y2  # (torch.nn.functional.tanh(x @ model[0].weight) @ model[2].weight)[1].item()\n",
    "y4 = f(sigma4)              # torch.nn.functional.tanh(torch.nn.functional.tanh(x @ model[0].weight) @ model[2].weight)[1].item()\n",
    "\n",
    "sigma = w9 * y3 + w10 * y4\n",
    "y_pred = sigma\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check\n",
    "# print(sigma1, (x @ model[0].weight)[0].item())\n",
    "# print(y1, torch.nn.functional.tanh(x @ model[0].weight)[0].item())\n",
    "# print(sigma2, (x @ model[0].weight)[1].item())\n",
    "# print(y2, torch.nn.functional.tanh(x @ model[0].weight)[1].item())\n",
    "\n",
    "# print(sigma3, (torch.nn.functional.tanh(x @ model[0].weight) @ model[2].weight)[0].item())\n",
    "# print(y3, torch.nn.functional.tanh(torch.nn.functional.tanh(x @ model[0].weight) @ model[2].weight)[0].item())\n",
    "# print(sigma4, (torch.nn.functional.tanh(x @ model[0].weight) @ model[2].weight)[1].item())\n",
    "# print(y4, torch.nn.functional.tanh(torch.nn.functional.tanh(x @ model[0].weight) @ model[2].weight)[1].item())\n",
    "\n",
    "# print(sigma, (torch.nn.functional.tanh(torch.nn.functional.tanh(x @ model[0].weight) @ model[2].weight) @ model[4].weight.T)[0].item())\n",
    "# print(y_pred, torch.nn.functional.tanh(torch.nn.functional.tanh(x @ model[0].weight) @ model[2].weight) @ model[4].weight.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss is the mean squared error between the predicted and true values\n",
    "(y_pred - y_true)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.functional.tanh(\n",
    "#     torch.nn.functional.tanh(\n",
    "#         x @ model[0].weight\n",
    "#     ) @ model[2].weight\n",
    "# ) @ model[4].weight.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.functional.tanh(\n",
    "#     torch.nn.functional.tanh(\n",
    "#         x @ model[0].weight.T\n",
    "#     ) @ model[2].weight.T\n",
    "# ) @ model[4].weight.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model[4].weight @ torch.nn.functional.tanh(\n",
    "#     model[2].weight @\n",
    "#     torch.nn.functional.tanh(\n",
    "#         model[0].weight @ x\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = loss_fn(y_pred, y_true)\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = nnfig.init_figure(size_x=8, size_y=4)\n",
    "\n",
    "HSPACE = 6\n",
    "VSPACE = 4\n",
    "\n",
    "# Synapse #####################################\n",
    "\n",
    "# Layer 1-2\n",
    "nnfig.draw_synapse(ax, (0,  VSPACE), (HSPACE,  VSPACE), label=tex(STR_WEIGHT + \"_1\"), label_position=0.4)\n",
    "nnfig.draw_synapse(ax, (0, -VSPACE), (HSPACE,  VSPACE), color=\"lightgray\")\n",
    "\n",
    "nnfig.draw_synapse(ax, (0,  VSPACE), (HSPACE, -VSPACE), color=\"lightgray\")\n",
    "nnfig.draw_synapse(ax, (0, -VSPACE), (HSPACE, -VSPACE), color=\"lightgray\")\n",
    "\n",
    "# Layer 2-3\n",
    "nnfig.draw_synapse(ax, (HSPACE,  VSPACE), (2*HSPACE,  VSPACE), label=tex(STR_WEIGHT + \"_2\"), label_position=0.4)\n",
    "nnfig.draw_synapse(ax, (HSPACE, -VSPACE), (2*HSPACE,  VSPACE), color=\"lightgray\")\n",
    "\n",
    "nnfig.draw_synapse(ax, (HSPACE,  VSPACE), (2*HSPACE, -VSPACE), label=tex(STR_WEIGHT + \"_3\"), label_position=0.4)\n",
    "nnfig.draw_synapse(ax, (HSPACE, -VSPACE), (2*HSPACE, -VSPACE), color=\"lightgray\")\n",
    "\n",
    "# Layer 3-4\n",
    "nnfig.draw_synapse(ax, (2*HSPACE,  VSPACE), (3*HSPACE, 0), label=tex(STR_WEIGHT + \"_4\"), label_position=0.4)\n",
    "nnfig.draw_synapse(ax, (2*HSPACE, -VSPACE), (3*HSPACE, 0), label=tex(STR_WEIGHT + \"_5\"), label_position=0.4, label_offset_y=-0.8)\n",
    "\n",
    "# Neuron ######################################\n",
    "\n",
    "# Layer 1 (input)\n",
    "nnfig.draw_neuron(ax, (0,  VSPACE), 0.5, empty=True)\n",
    "nnfig.draw_neuron(ax, (0, -VSPACE), 0.5, empty=True, line_color=\"lightgray\")\n",
    "\n",
    "# Layer 2\n",
    "nnfig.draw_neuron(ax, (HSPACE,  VSPACE), 1, ag_func=\"sum\", tr_func=\"sigmoid\")\n",
    "nnfig.draw_neuron(ax, (HSPACE, -VSPACE), 1, ag_func=\"sum\", tr_func=\"sigmoid\", line_color=\"lightgray\")\n",
    "\n",
    "# Layer 3\n",
    "nnfig.draw_neuron(ax, (2*HSPACE,  VSPACE), 1, ag_func=\"sum\", tr_func=\"sigmoid\")\n",
    "nnfig.draw_neuron(ax, (2*HSPACE, -VSPACE), 1, ag_func=\"sum\", tr_func=\"sigmoid\")\n",
    "\n",
    "# Layer 4\n",
    "nnfig.draw_neuron(ax, (3*HSPACE, 0), 1, ag_func=\"sum\", tr_func=\"sigmoid\")\n",
    "\n",
    "# Text ########################################\n",
    "\n",
    "# Layer 1 (input)\n",
    "plt.text(x=0.5, y=VSPACE+1, s=tex(STR_SIGOUT + \"_i\"), fontsize=12)\n",
    "\n",
    "# Layer 2\n",
    "plt.text(x=HSPACE-1.25, y=VSPACE+1.5, s=tex(STR_POT + \"_1\"), fontsize=12)\n",
    "plt.text(x=HSPACE+0.4,  y=VSPACE+1.5, s=tex(STR_SIGOUT + \"_1\"), fontsize=12)\n",
    "\n",
    "# Layer 3\n",
    "plt.text(x=2*HSPACE-1.25, y=VSPACE+1.5, s=tex(STR_POT + \"_2\"), fontsize=12)\n",
    "plt.text(x=2*HSPACE+0.4,  y=VSPACE+1.5, s=tex(STR_SIGOUT + \"_2\"), fontsize=12)\n",
    "\n",
    "plt.text(x=2*HSPACE-1.25, y=-VSPACE-1.8, s=tex(STR_POT + \"_3\"), fontsize=12)\n",
    "plt.text(x=2*HSPACE+0.4,  y=-VSPACE-1.8, s=tex(STR_SIGOUT + \"_3\"), fontsize=12)\n",
    "\n",
    "# Layer 4\n",
    "plt.text(x=3*HSPACE-1.25, y=1.5, s=tex(STR_POT + \"_o\"), fontsize=12)\n",
    "plt.text(x=3*HSPACE+0.4,  y=1.5, s=tex(STR_SIGOUT + \"_o\"), fontsize=12)\n",
    "\n",
    "plt.text(x=3*HSPACE+2,  y=-0.3,\n",
    "         s=tex(STR_ERRFUNC + \" = (\" + STR_SIGOUT + \"_o - \" + STR_SIGOUT_DES + \"_o)^2/2\"),\n",
    "         fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "error.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gradients\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Gradient for {name}: {param.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward computation of $\\frac{\\partial \\errfunc}{\\partial \\weight_{10}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = nnfig.init_figure(size_x=8, size_y=4)\n",
    "\n",
    "HSPACE = 6\n",
    "VSPACE = 4\n",
    "\n",
    "# Synapse #####################################\n",
    "\n",
    "# Layer 1-2\n",
    "nnfig.draw_synapse(\n",
    "    ax, (0,  VSPACE), (HSPACE,  VSPACE),\n",
    "    # label=tex(STR_WEIGHT + \"_1\"), label_position=0.4,\n",
    "    color=\"lightgray\"\n",
    ")\n",
    "nnfig.draw_synapse(\n",
    "    ax, (0, -VSPACE), (HSPACE,  VSPACE),\n",
    "    # label=tex(STR_WEIGHT + \"_3\"), label_position=0.25, label_offset_y=-0.8,\n",
    "    color=\"lightgray\"\n",
    ")\n",
    "\n",
    "nnfig.draw_synapse(\n",
    "    ax, (0,  VSPACE), (HSPACE, -VSPACE),\n",
    "    # label=tex(STR_WEIGHT + \"_2\"), label_position=0.25,\n",
    "    color=\"lightgray\"\n",
    ")\n",
    "nnfig.draw_synapse(\n",
    "    ax, (0, -VSPACE), (HSPACE, -VSPACE),\n",
    "    # label=tex(STR_WEIGHT + \"_4\"), label_position=0.4, label_offset_y=-0.8,\n",
    "    color=\"lightgray\"\n",
    ")\n",
    "\n",
    "# Layer 2-3\n",
    "nnfig.draw_synapse(\n",
    "    ax, (HSPACE,  VSPACE), (2*HSPACE,  VSPACE),\n",
    "    # label=tex(STR_WEIGHT + \"_5\"), label_position=0.4,\n",
    "    color=\"lightgray\"\n",
    ")\n",
    "nnfig.draw_synapse(\n",
    "    ax, (HSPACE, -VSPACE), (2*HSPACE,  VSPACE),\n",
    "    # label=tex(STR_WEIGHT + \"_7\"), label_position=0.25, label_offset_y=-0.8,\n",
    "    color=\"lightgray\"\n",
    ")\n",
    "\n",
    "nnfig.draw_synapse(\n",
    "    ax, (HSPACE,  VSPACE), (2*HSPACE, -VSPACE),\n",
    "    # label=tex(STR_WEIGHT + \"_6\"), label_position=0.25,\n",
    "    color=\"lightgray\"\n",
    ")\n",
    "nnfig.draw_synapse(\n",
    "    ax, (HSPACE, -VSPACE), (2*HSPACE, -VSPACE),\n",
    "    # label=tex(STR_WEIGHT + \"_8\"), label_position=0.4, label_offset_y=-0.8,\n",
    "    color=\"lightgray\"\n",
    ")\n",
    "\n",
    "# Layer 3-4\n",
    "nnfig.draw_synapse(\n",
    "    ax, (2*HSPACE,  VSPACE), (3*HSPACE, 0),\n",
    "    # label=tex(STR_WEIGHT + \"_9\"), label_position=0.4,\n",
    "    color=\"lightgray\"\n",
    ")\n",
    "nnfig.draw_synapse(\n",
    "    ax, (2*HSPACE, -VSPACE), (3*HSPACE, 0),\n",
    "    label=tex(STR_WEIGHT + \"_{10}\"), label_position=0.4, label_offset_y=-0.8\n",
    ")\n",
    "\n",
    "nnfig.draw_synapse(ax, (3*HSPACE, 0), (3*HSPACE + 2, 0))\n",
    "\n",
    "# Neuron ######################################\n",
    "\n",
    "# Layer 1 (input)\n",
    "nnfig.draw_neuron(ax, (0,  VSPACE), 0.5, empty=True, line_color=\"lightgray\")\n",
    "nnfig.draw_neuron(ax, (0, -VSPACE), 0.5, empty=True, line_color=\"lightgray\")\n",
    "\n",
    "# Layer 2\n",
    "nnfig.draw_neuron(ax, (HSPACE,  VSPACE), 1, ag_func=\"sum\", tr_func=\"sigmoid\", line_color=\"lightgray\")\n",
    "nnfig.draw_neuron(ax, (HSPACE, -VSPACE), 1, ag_func=\"sum\", tr_func=\"sigmoid\", line_color=\"lightgray\")\n",
    "\n",
    "# Layer 3\n",
    "nnfig.draw_neuron(ax, (2*HSPACE,  VSPACE), 1, ag_func=\"sum\", tr_func=\"sigmoid\", line_color=\"lightgray\")\n",
    "nnfig.draw_neuron(ax, (2*HSPACE, -VSPACE), 1, ag_func=\"sum\", tr_func=\"sigmoid\", line_color=\"lightgray\")\n",
    "\n",
    "# Layer 4\n",
    "nnfig.draw_neuron(ax, (3*HSPACE, 0), 1, ag_func=\"sum\", tr_func=\"identity\")\n",
    "\n",
    "# Text ########################################\n",
    "\n",
    "# Layer 1 (input)\n",
    "# plt.text(x=0.5, y=VSPACE+1, s=tex(STR_SIGOUT + \"_i\"), fontsize=12)\n",
    "# plt.text(x=-1.7, y=VSPACE,      s=tex(STR_SIGIN + \"_1\"), fontsize=12)\n",
    "# plt.text(x=-1.7, y=-VSPACE-0.2, s=tex(STR_SIGIN + \"_2\"), fontsize=12)\n",
    "\n",
    "# Layer 2\n",
    "# plt.text(x=HSPACE-1.25, y=VSPACE+1.5, s=tex(STR_POT + \"_1\"), fontsize=12)\n",
    "# plt.text(x=HSPACE+0.4,  y=VSPACE+1.5, s=tex(STR_SIGOUT + \"_1\"), fontsize=12)\n",
    "\n",
    "# plt.text(x=HSPACE-1.25, y=-VSPACE-1.8, s=tex(STR_POT + \"_2\"), fontsize=12)\n",
    "# plt.text(x=HSPACE+0.4,  y=-VSPACE-1.8, s=tex(STR_SIGOUT + \"_2\"), fontsize=12)\n",
    "\n",
    "# Layer 3\n",
    "# plt.text(x=2*HSPACE-1.25, y=VSPACE+1.5, s=tex(STR_POT + \"_3\"), fontsize=12)\n",
    "# plt.text(x=2*HSPACE+0.4,  y=VSPACE+1.5, s=tex(STR_SIGOUT + \"_3\"), fontsize=12)\n",
    "\n",
    "# plt.text(x=2*HSPACE-1.25, y=-VSPACE-1.8, s=tex(STR_POT + \"_4\"), fontsize=12)\n",
    "# plt.text(x=2*HSPACE-0.2,  y=-VSPACE-1.8, s=tex(STR_POT + \"_4\"), fontsize=12, color=\"green\")\n",
    "plt.text(x=2*HSPACE+1.,  y=-VSPACE-1., s=tex(STR_SIGOUT + \"_4\"), fontsize=12)\n",
    "\n",
    "# Layer 4\n",
    "# plt.text(x=3*HSPACE-1.25, y=1.5, s=tex(STR_POT + \"_o\"), fontsize=12)\n",
    "# plt.text(x=3*HSPACE+0.4,  y=1.5, s=tex(STR_SIGOUT + \"_o\"), fontsize=12)\n",
    "\n",
    "plt.text(x=3*HSPACE-0.3,  y=-1.8, s=tex(STR_POT), fontsize=12, color=\"green\")\n",
    "plt.text(x=3*HSPACE+2.5,  y=-0.3, s=tex(STR_SIGOUT), fontsize=12, color=\"red\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the chain rule:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\errfunc}{\\partial \\weight_{10}} =\n",
    "\\frac{\\partial \\errfunc}{\\partial \\color{red}{\\sigout}}\n",
    "\\frac{\\partial \\color{red}{\\sigout}}{\\partial \\color{green}{\\pot}} ~\n",
    "\\frac{\\partial \\color{green}{\\pot}}{\\partial \\weight_{10}} ~\n",
    "$$\n",
    "\n",
    "knowing that:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\errfunc}{\\partial \\color{red}{\\sigout}}              &= 2 (\\sigout - \\sigoutdes) \\\\\n",
    "\\frac{\\partial \\color{red}{\\sigout}}{\\partial \\color{green}{\\pot}}   &= f'(\\pot) \\\\\n",
    "\\frac{\\partial \\color{green}{\\pot}}{\\partial \\weight_{10}}           &= \\sigout_4 \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "we can write:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\errfunc}{\\partial \\weight_{10}} = 2(\\sigout - \\sigoutdes) \\cdot f'(\\pot) \\cdot \\sigout_4\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive detailed computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the forward computation in a (naive) detailed way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_E_w10 = 2 * (y_pred - y_true) * y4\n",
    "grad_E_w10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algebraic computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rewrite the forward computation in a less naive way (using linear algebra)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = torch.nn.functional.tanh\n",
    "\n",
    "# h1 = f(x[0] @ model.weight_ih_l0 + h0 @ model.weight_hh_l0)   # hidden state at time step 1\n",
    "# h2 = f(x[1] @ model.weight_ih_l0 + h1 @ model.weight_hh_l0)   # hidden state at time step 2\n",
    "# h3 = f(x[2] @ model.weight_ih_l0 + h2 @ model.weight_hh_l0)   # hidden state at time step 3\n",
    "\n",
    "# print(f\"Output for time step 1:\\nh1 = \\n{ h1 }\\n\\n\")\n",
    "# print(f\"Output for time step 2:\\nh2 = \\n{ h2 }\\n\\n\")\n",
    "# print(f\"Output for time step 3:\\nh3 = \\n{ h3 }\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward computation of $\\frac{\\partial \\errfunc}{\\partial \\weight_{9}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = nnfig.init_figure(size_x=8, size_y=4)\n",
    "\n",
    "HSPACE = 6\n",
    "VSPACE = 4\n",
    "\n",
    "# Synapse #####################################\n",
    "\n",
    "# Layer 1-2\n",
    "nnfig.draw_synapse(\n",
    "    ax, (0,  VSPACE), (HSPACE,  VSPACE),\n",
    "    # label=tex(STR_WEIGHT + \"_1\"), label_position=0.4,\n",
    "    color=\"lightgray\"\n",
    ")\n",
    "nnfig.draw_synapse(\n",
    "    ax, (0, -VSPACE), (HSPACE,  VSPACE),\n",
    "    # label=tex(STR_WEIGHT + \"_3\"), label_position=0.25, label_offset_y=-0.8,\n",
    "    color=\"lightgray\"\n",
    ")\n",
    "\n",
    "nnfig.draw_synapse(\n",
    "    ax, (0,  VSPACE), (HSPACE, -VSPACE),\n",
    "    # label=tex(STR_WEIGHT + \"_2\"), label_position=0.25,\n",
    "    color=\"lightgray\"\n",
    ")\n",
    "nnfig.draw_synapse(\n",
    "    ax, (0, -VSPACE), (HSPACE, -VSPACE),\n",
    "    # label=tex(STR_WEIGHT + \"_4\"), label_position=0.4, label_offset_y=-0.8,\n",
    "    color=\"lightgray\"\n",
    ")\n",
    "\n",
    "# Layer 2-3\n",
    "nnfig.draw_synapse(\n",
    "    ax, (HSPACE,  VSPACE), (2*HSPACE,  VSPACE),\n",
    "    # label=tex(STR_WEIGHT + \"_5\"), label_position=0.4,\n",
    "    color=\"lightgray\"\n",
    ")\n",
    "nnfig.draw_synapse(\n",
    "    ax, (HSPACE, -VSPACE), (2*HSPACE,  VSPACE),\n",
    "    # label=tex(STR_WEIGHT + \"_7\"), label_position=0.25, label_offset_y=-0.8,\n",
    "    color=\"lightgray\"\n",
    ")\n",
    "\n",
    "nnfig.draw_synapse(\n",
    "    ax, (HSPACE,  VSPACE), (2*HSPACE, -VSPACE),\n",
    "    # label=tex(STR_WEIGHT + \"_6\"), label_position=0.25,\n",
    "    color=\"lightgray\"\n",
    ")\n",
    "nnfig.draw_synapse(\n",
    "    ax, (HSPACE, -VSPACE), (2*HSPACE, -VSPACE),\n",
    "    # label=tex(STR_WEIGHT + \"_8\"), label_position=0.4, label_offset_y=-0.8,\n",
    "    color=\"lightgray\"\n",
    ")\n",
    "\n",
    "# Layer 3-4\n",
    "nnfig.draw_synapse(\n",
    "    ax, (2*HSPACE,  VSPACE), (3*HSPACE, 0),\n",
    "    label=tex(STR_WEIGHT + \"_9\"), label_position=0.4\n",
    ")\n",
    "nnfig.draw_synapse(\n",
    "    ax, (2*HSPACE, -VSPACE), (3*HSPACE, 0),\n",
    "    # label=tex(STR_WEIGHT + \"_{10}\"), label_position=0.4, label_offset_y=-0.8,\n",
    "    color=\"lightgray\"\n",
    ")\n",
    "\n",
    "nnfig.draw_synapse(ax, (3*HSPACE, 0), (3*HSPACE + 2, 0))\n",
    "\n",
    "# Neuron ######################################\n",
    "\n",
    "# Layer 1 (input)\n",
    "nnfig.draw_neuron(ax, (0,  VSPACE), 0.5, empty=True, line_color=\"lightgray\")\n",
    "nnfig.draw_neuron(ax, (0, -VSPACE), 0.5, empty=True, line_color=\"lightgray\")\n",
    "\n",
    "# Layer 2\n",
    "nnfig.draw_neuron(ax, (HSPACE,  VSPACE), 1, ag_func=\"sum\", tr_func=\"sigmoid\", line_color=\"lightgray\")\n",
    "nnfig.draw_neuron(ax, (HSPACE, -VSPACE), 1, ag_func=\"sum\", tr_func=\"sigmoid\", line_color=\"lightgray\")\n",
    "\n",
    "# Layer 3\n",
    "nnfig.draw_neuron(ax, (2*HSPACE,  VSPACE), 1, ag_func=\"sum\", tr_func=\"sigmoid\", line_color=\"lightgray\")\n",
    "nnfig.draw_neuron(ax, (2*HSPACE, -VSPACE), 1, ag_func=\"sum\", tr_func=\"sigmoid\", line_color=\"lightgray\")\n",
    "\n",
    "# Layer 4\n",
    "nnfig.draw_neuron(ax, (3*HSPACE, 0), 1, ag_func=\"sum\", tr_func=\"identity\")\n",
    "\n",
    "# Text ########################################\n",
    "\n",
    "# Layer 1 (input)\n",
    "# plt.text(x=0.5, y=VSPACE+1, s=tex(STR_SIGOUT + \"_i\"), fontsize=12)\n",
    "# plt.text(x=-1.7, y=VSPACE,      s=tex(STR_SIGIN + \"_1\"), fontsize=12)\n",
    "# plt.text(x=-1.7, y=-VSPACE-0.2, s=tex(STR_SIGIN + \"_2\"), fontsize=12)\n",
    "\n",
    "# Layer 2\n",
    "# plt.text(x=HSPACE-1.25, y=VSPACE+1.5, s=tex(STR_POT + \"_1\"), fontsize=12)\n",
    "# plt.text(x=HSPACE+0.4,  y=VSPACE+1.5, s=tex(STR_SIGOUT + \"_1\"), fontsize=12)\n",
    "\n",
    "# plt.text(x=HSPACE-1.25, y=-VSPACE-1.8, s=tex(STR_POT + \"_2\"), fontsize=12)\n",
    "# plt.text(x=HSPACE+0.4,  y=-VSPACE-1.8, s=tex(STR_SIGOUT + \"_2\"), fontsize=12)\n",
    "\n",
    "# Layer 3\n",
    "# plt.text(x=2*HSPACE-1.25, y=VSPACE+1.5, s=tex(STR_POT + \"_3\"), fontsize=12)\n",
    "plt.text(x=2*HSPACE+0.4,  y=VSPACE+1.5, s=tex(STR_SIGOUT + \"_3\"), fontsize=12)\n",
    "\n",
    "# plt.text(x=2*HSPACE-1.25, y=-VSPACE-1.8, s=tex(STR_POT + \"_4\"), fontsize=12)\n",
    "# plt.text(x=2*HSPACE-0.2,  y=-VSPACE-1.8, s=tex(STR_POT + \"_4\"), fontsize=12, color=\"green\")\n",
    "# plt.text(x=2*HSPACE+1.,  y=-VSPACE-1., s=tex(STR_SIGOUT + \"_4\"), fontsize=12)\n",
    "\n",
    "# Layer 4\n",
    "# plt.text(x=3*HSPACE-1.25, y=1.5, s=tex(STR_POT + \"_o\"), fontsize=12)\n",
    "# plt.text(x=3*HSPACE+0.4,  y=1.5, s=tex(STR_SIGOUT + \"_o\"), fontsize=12)\n",
    "\n",
    "plt.text(x=3*HSPACE-0.3,  y=-1.8, s=tex(STR_POT), fontsize=12, color=\"green\")\n",
    "plt.text(x=3*HSPACE+2.5,  y=-0.3, s=tex(STR_SIGOUT), fontsize=12, color=\"red\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the chain rule:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\errfunc}{\\partial \\weight_{9}} =\n",
    "\\frac{\\partial \\errfunc}{\\partial \\color{red}{\\sigout}}\n",
    "\\frac{\\partial \\color{red}{\\sigout}}{\\partial \\color{green}{\\pot}} ~\n",
    "\\frac{\\partial \\color{green}{\\pot}}{\\partial \\weight_{9}} ~\n",
    "$$\n",
    "\n",
    "knowing that:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\errfunc}{\\partial \\color{red}{\\sigout}}              &= 2 (\\sigout - \\sigoutdes) \\\\\n",
    "\\frac{\\partial \\color{red}{\\sigout}}{\\partial \\color{green}{\\pot}}   &= f'(\\pot) \\\\\n",
    "\\frac{\\partial \\color{green}{\\pot}}{\\partial \\weight_{9}}           &= \\sigout_3 \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "we can write:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\errfunc}{\\partial \\weight_{9}} = 2(\\sigout - \\sigoutdes) \\cdot f'(\\pot) \\cdot \\sigout_3\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive detailed computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the forward computation in a (naive) detailed way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_E_w9 = 2 * (y_pred - y_true) * y3\n",
    "grad_E_w9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algebraic computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rewrite the forward computation in a less naive way (using linear algebra)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
